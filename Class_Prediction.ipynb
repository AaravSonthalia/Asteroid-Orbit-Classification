{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb_gby1a8jBK"
      },
      "outputs": [],
      "source": [
        "# IMPORTING\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "# custom neural network\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, CategoryEncoding, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3eIsIMF80gm"
      },
      "outputs": [],
      "source": [
        "# reading data set x and y into variables\n",
        "xPath = \"/content/drive/MyDrive/Inspirit AI Research/dataSetX.csv\"\n",
        "X = pd.read_csv(xPath,index_col=0)\n",
        "yPath = \"/content/drive/MyDrive/Inspirit AI Research/dataSetY.csv\"\n",
        "y = pd.read_csv(yPath,index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hAO3h_nsHxf"
      },
      "outputs": [],
      "source": [
        "# In the description of asteroid classes, it seems that each class in the data set only differs by the perihelion, aphelion, and semi major axis sizes.\n",
        "# This is taken from a description of the data set itself: https://ssd-api.jpl.nasa.gov/doc/sbdb_filter.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wc6KBv86GnW"
      },
      "outputs": [],
      "source": [
        "# removing MBAs to decrease runtime significantly\n",
        "idx = (y[\"class\"]!=\"MBA\").to_numpy()\n",
        "XnoMBA = X[idx]\n",
        "ynoMBA = y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgDjdjYMu85m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9a66e3-10de-40be-c114-510bafdd22e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102570, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "XnoMBA.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ecIbXWzsMhU"
      },
      "outputs": [],
      "source": [
        "# It seems that MBAs are the most abundant asteroid class and are helpful when trying to graph the Kirkwood gaps. I do not see any big problems that\n",
        "# arise by removing MBAs from my data other than there being a gap in the semi major axis and perihelion values between IMB and OMB where MBA was."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HkHho8v7Gd_"
      },
      "outputs": [],
      "source": [
        "# look to see the new data set\n",
        "plt.figure()\n",
        "plt.hist(ynoMBA)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2bJqssF9zXA"
      },
      "outputs": [],
      "source": [
        "# DATA AUGMENTATION\n",
        "# using SMOTE as data augmentation\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# creating an instance of the smote class\n",
        "sm = SMOTE(random_state=42,k_neighbors=3)\n",
        "# using SMOTE on the data\n",
        "X_res, y_res = sm.fit_resample(XnoMBA, ynoMBA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ist4FgKZ8mav"
      },
      "outputs": [],
      "source": [
        "# look to see the new augmented data set\n",
        "plt.figure()\n",
        "plt.hist(y_res)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4157oAo89Nqq"
      },
      "outputs": [],
      "source": [
        "# splitting data into testing and training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64B0LnvB-X4R"
      },
      "outputs": [],
      "source": [
        "# this function will create a confusion matrix\n",
        "def displayConfusionMatrix(prediction):\n",
        "  # creating the matrix\n",
        "  cm = confusion_matrix(y_test, prediction, labels=ynoMBA[\"class\"].unique())\n",
        "  # displaying the matrix\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ynoMBA[\"class\"].unique())\n",
        "  # plotting the matrix\n",
        "  disp.plot(cmap=\"Reds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSrKbw0B-bFc"
      },
      "outputs": [],
      "source": [
        "# this function will train and test a model\n",
        "def trainTestModel(model):\n",
        "  # training\n",
        "  model.fit(X_train, y_train.values.ravel())\n",
        "  # testing\n",
        "  prediction = model.predict(X_test)\n",
        "  # accuracy\n",
        "  accuracy = accuracy_score(y_test, prediction)\n",
        "  # printing the accuracy\n",
        "  print('Model % Accuracy: {:.2%}'.format(accuracy))\n",
        "  # returning the prediction\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV76T1lbAkOQ"
      },
      "outputs": [],
      "source": [
        "# this function will run the model\n",
        "def runModel(model):\n",
        "  # getting the prediction\n",
        "  prediction = trainTestModel(model)\n",
        "  # displaying the confusion matrix\n",
        "  displayConfusionMatrix(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrNmAi6dLon7"
      },
      "outputs": [],
      "source": [
        "# \"A simple K-Nearest Neighbor approach to predicting the orbit class based on aphelion and perihelion should work pretty well!\" Quote taken from\n",
        "# the exlporation of the dataset on kaggle about what algorithm to use and how to use it to classify the class of an asteroid based on its orbit. The\n",
        "# paper by Hossain, however, shows that an XGBoost model has a higher accuracy than a K-Nearest Neighbor model with an accuracy of 99.99%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiICS4Ht-1hZ"
      },
      "outputs": [],
      "source": [
        "# LOGISTIC REGRESSION\n",
        "logistic_model = LogisticRegression(max_iter=500) # used to be 200 max iter\n",
        "runModel(logistic_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXW1d5bK-5lV"
      },
      "outputs": [],
      "source": [
        "# RANDOM FOREST CLASSIFIER\n",
        "forest_model = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "runModel(forest_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXAR8_CM_Dxc"
      },
      "outputs": [],
      "source": [
        "# K-NEAREST NEIGHBOR\n",
        "knn_model = KNeighborsClassifier(n_neighbors=15, algorithm='auto') # used to be 1 n neighbors\n",
        "runModel(knn_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkikxzLs3S0I"
      },
      "outputs": [],
      "source": [
        "# In the MLP classifier, the hidden layer sizes takes in as many parameters as there will be hidden layers and the number of the paramater\n",
        "# is the number of nodes in the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng2ki9R4BDnJ"
      },
      "outputs": [],
      "source": [
        "# NEURAL NETWORKS\n",
        "mlp_model1 = MLPClassifier(hidden_layer_sizes=(10,10,10))\n",
        "runModel(mlp_model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fm9h-78BLwb"
      },
      "outputs": [],
      "source": [
        "mlp_model1 = MLPClassifier(hidden_layer_sizes=(3,3,3))\n",
        "runModel(mlp_model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuajlJKzBNEI"
      },
      "outputs": [],
      "source": [
        "mlp_model1 = MLPClassifier(hidden_layer_sizes=(10,10,10,10,10))\n",
        "runModel(mlp_model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KTfouy8BOZY"
      },
      "outputs": [],
      "source": [
        "mlp_model1 = MLPClassifier(hidden_layer_sizes=(5,5,5,5,5)) # best neural network\n",
        "runModel(mlp_model1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function will create and train a custom keras neural network\n",
        "#def train(config=None):\n",
        "# setting random seed\n",
        "# removes the randomness in my trials\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "\n",
        "# weights and biases\n",
        "!pip install wandb -qU\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.login()\n",
        "\n",
        "# running weights and biases\n",
        "run = wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"Asteroid Orbital Class Prediction\",\n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"hidden_layer_architecture\" : \"16,16,16,16,16\",\n",
        "      \"num_layers\" : 5,\n",
        "      \"num_nodes\" : 16,\n",
        "      \"epochs\": 150,\n",
        "      \"activation_function\": \"relu\",\n",
        "      \"batch_size\": 1000,\n",
        "      })\n",
        "config = wandb.config # use this to configure the experiement\n",
        "\n",
        "# TRANSLATING Y VECTOR VALUES TO NUMERICAL VALUES\n",
        "# one hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "y_trainOneHot = ohe.fit_transform(y_train).toarray()\n",
        "y_testOneHot = ohe.fit_transform(y_test).toarray()\n",
        "# takes first category and sets it to index 0, takes second one and sets it to index 1, and goes on\n",
        "\n",
        "# CREATING CUSTOM NN WITH KERAS\n",
        "# n layers of x nodes\n",
        "nn_model = Sequential()\n",
        "nn_model.add(Dense(12, input_shape=(12,)))\n",
        "for i in range(config.num_layers):\n",
        "  nn_model.add(Dense(config.num_nodes, activation=config.activation_function))\n",
        "nn_model.add(Dense(12, activation=\"softmax\")) # last activation function MUST remain softmax, only used for output layer\n",
        "\n",
        "# Dropout - technique used in machine learning:\n",
        "# Specify a value for the droput rate (between 0 and 1)\n",
        "# During training, for each layer where dropout is implemented, some percent of the connections between nodes will be ommited\n",
        "# Dropped connections are randomly chosen\n",
        "# You can create larger models (more layers and nodes) and effectively create an average of many values\n",
        "# You can build complexity into model without relying on the specific features\n",
        "\n",
        "# Only really count the number of hidden layers (not input (first) or output (last) layer)\n",
        "# NN is considered \"deep\" if it has 3+ hidden layers\n",
        "# 1000 nodes is usually considered a lot. Really depends on the resources you have (hardware, software, etc)\n",
        "# Epochs times batch size should be near the amount of samples you have (958524) since that number is the total amount of samples that will get tested\n",
        "\n",
        "# https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5\n",
        "nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# training\n",
        "modelHistory = nn_model.fit(X_train, y_trainOneHot, epochs=config.epochs, batch_size=config.batch_size, validation_data=(X_test, y_testOneHot), callbacks=[WandbCallback()])\n",
        "\n",
        "# saving the model with keras to save the generated weights\n",
        "# no need to regenerate the weights if we want to modify an already tested model\n",
        "# automatically overwrites previous save if file name is same, need to change file name to save a new model and keep old one\n",
        "nn_model.save(\"/content/drive/MyDrive/Inspirit AI Research/model.keras\")\n",
        "\n",
        "# getting training and testing accuracy\n",
        "histAccuracy = modelHistory.history['accuracy']\n",
        "histValAccuracy = modelHistory.history['val_accuracy']\n",
        "\n",
        "# plotting accuracy over epochs\n",
        "plt.figure()\n",
        "plt.plot(histAccuracy, label=\"Train\")\n",
        "plt.plot(histValAccuracy, label=\"Validation\")\n",
        "plt.xlabel(\"Epoch Number\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# finishing the run\n",
        "run.finish()\n",
        "\n",
        "# calling train function\n",
        "#train()"
      ],
      "metadata": {
        "id": "Ix9esADCQQkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMETER TUNING WITH SWEEPS\n",
        "# creating a sweep to tune hyperparameters\n",
        "sweep_config = {'method' : 'random'} # random search randomly picks valuesa and tests them\n",
        "\n",
        "# we want to maximize the value accuracy\n",
        "metric = {\n",
        "    'name' : 'val_accuracy',\n",
        "    'goal' : 'maximize',\n",
        "}\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "# setting the values for the parameters\n",
        "parameters_dict = {\n",
        "    'activation_function' : {'values' : ['relu', 'tanh', 'sigmoid']},\n",
        "    'num_layers' : {'values' : [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
        "    'num_nodes' : {'values' : [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]},\n",
        "    'epochs' : {'values' : [100, 125, 150, 175, 200]},\n",
        "    'batch_size' : {'values' : [1000, 1250, 1500, 1750, 2000]},\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "# initializing and running the sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Asteroid Orbital Class Prediction\")\n",
        "wandb.agent(sweep_id, train, count=100) # 6750 different parameter combinations"
      ],
      "metadata": {
        "id": "WI0MlNxKDZ9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p66OOkt-Z06p"
      },
      "outputs": [],
      "source": [
        "# Testing: https://wandb.ai/aaravsonthalia/Asteroid%20Orbital%20Class%20Prediction?workspace=user-aaravsonthalia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIsF3cd6hL4t"
      },
      "outputs": [],
      "source": [
        "# this function will reverse a one hot encoded array\n",
        "def undoOneHot(oneHotArr, originalValArr):\n",
        "  # creating empty array for reversed values\n",
        "  labels = np.empty(oneHotArr.shape[0],dtype=object)\n",
        "  # for each array in the one hot encoded matrix\n",
        "  for i, array in enumerate(oneHotArr):\n",
        "    # get the max value index\n",
        "    maxIdx = np.argmax(array)\n",
        "    # turn that into the original value\n",
        "    originalVal = originalValArr[maxIdx]\n",
        "    # add it to the reversed value array\n",
        "    labels[i] = originalVal\n",
        "  # returning\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7VOS5nr8Pol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322a38fb-e4e3-4df3-a54b-51836486e077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2127/2127 [==============================] - 4s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# testing\n",
        "y_predOneHot = nn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta8qyXPDCzJp"
      },
      "outputs": [],
      "source": [
        "# array for the original values before one hot encoding\n",
        "orbitClassArr = ohe.categories_[0].copy()\n",
        "# getting the actual predictions\n",
        "y_pred = undoOneHot(y_predOneHot, orbitClassArr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqCdNK8A8Q15"
      },
      "outputs": [],
      "source": [
        "# displaying the confusion matrix\n",
        "displayConfusionMatrix(y_pred)\n",
        "# getting and printing accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# printing the accuracy\n",
        "print('Model % Accuracy: {:.2%}'.format(accuracy))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}